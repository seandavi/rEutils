install.packages('rEutils',contriburl=contrib.url('http://watson.nci.nih.gov/R/repos',type='source'))

Then, in R:

library(rEutils)
## set up an eSearchQuery
## See http://www.ncbi.nlm.nih.gov/corehtml/query/static/esearch_help.html
##   for details of what can be included as parameters
## "term" is what you would type into the pubmed search box....
esq = new("eSearchQuery",db='pubmed',term='Irizarry RA[auth]',retmax=500)
res = eSearch(esq)
res@count  ## The count of the number of results
res@idlist  ## The pubmed ids of the result


## To get document summaries:

### Note the use of the usehistory='y' parameter
esq = new("eSearchQuery",db='pubmed',term='Irizarry
RA[auth]',retmax=500,usehistory='y')
res = eSearch(esq)
esumquery = new("eSummaryQuery",res)
res2 = eSummary(esumquery)

### res2 now contains the document summary
### for each record.  This stored as raw
### XML, but you can use XML tools to parse
### out what you want.

library(annotate)
### Using EFETCH
### Note the power of the parser parameter!
### A "parser" must be a function that takes
### a string representing a URL and then reads from it
### Also note how the result (res) from a previous search
### is used as the basis for the fetch
efr2 = eFetch(res,parser=function(x) {tmp = xmlTreeParse(x);return(xmlApply(tmp,buildPubMedAbst))},retmode='xml')
length(efr2)  ## should be 54
efr2[[1]]     ## this is an object of type "pubMedAbst"
help("pubMedAbst-class")
sapply(efr2,authors)
sapply(efr2,articleTitle)



The efetch system still needs some work--this would be the better way
of getting your results.  If I have time in the next few days, I'll
look into making sure this works, also.